{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer #word stemmer class\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Bidirectional, LSTM, Dropout, BatchNormalization\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining path of data\n",
    "my_data = r\"C:\\Users\\Danish\\Desktop\\ZS_associates\\dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/Danish/Desktop/ZS_associates/dataset/train_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('C:/Users/Danish/Desktop/ZS_associates/dataset/test_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDLink</th>\n",
       "      <th>Title</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Topic</th>\n",
       "      <th>PublishDate</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>GooglePlus</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>SentimentTitle</th>\n",
       "      <th>SentimentHeadline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tr3CMgRv1N</td>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemetery</td>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemete...</td>\n",
       "      <td>USA TODAY</td>\n",
       "      <td>obama</td>\n",
       "      <td>2002-04-02 00:00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wc81vGp8qZ</td>\n",
       "      <td>A Look at the Health of the Chinese Economy</td>\n",
       "      <td>Tim Haywood, investment director business-unit...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>economy</td>\n",
       "      <td>2008-09-20 00:00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>-0.156386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zNGH03CrZH</td>\n",
       "      <td>Nouriel Roubini: Global Economy Not Back to 2008</td>\n",
       "      <td>Nouriel Roubini, NYU professor and chairman at...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>economy</td>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.425210</td>\n",
       "      <td>0.139754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3sM1H0W8ts</td>\n",
       "      <td>Finland GDP Expands In Q4</td>\n",
       "      <td>Finland's economy expanded marginally in the t...</td>\n",
       "      <td>RTT News</td>\n",
       "      <td>economy</td>\n",
       "      <td>2015-03-01 00:06:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wUbnxgvqaZ</td>\n",
       "      <td>Tourism, govt spending buoys Thai economy in J...</td>\n",
       "      <td>Tourism and public spending continued to boost...</td>\n",
       "      <td>The Nation - Thailand&amp;#39;s English news</td>\n",
       "      <td>economy</td>\n",
       "      <td>2015-03-01 00:11:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IDLink                                              Title  \\\n",
       "0  Tr3CMgRv1N   Obama Lays Wreath at Arlington National Cemetery   \n",
       "1  Wc81vGp8qZ        A Look at the Health of the Chinese Economy   \n",
       "2  zNGH03CrZH   Nouriel Roubini: Global Economy Not Back to 2008   \n",
       "3  3sM1H0W8ts                          Finland GDP Expands In Q4   \n",
       "4  wUbnxgvqaZ  Tourism, govt spending buoys Thai economy in J...   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  Obama Lays Wreath at Arlington National Cemete...   \n",
       "1  Tim Haywood, investment director business-unit...   \n",
       "2  Nouriel Roubini, NYU professor and chairman at...   \n",
       "3  Finland's economy expanded marginally in the t...   \n",
       "4  Tourism and public spending continued to boost...   \n",
       "\n",
       "                                     Source    Topic          PublishDate  \\\n",
       "0                                 USA TODAY    obama  2002-04-02 00:00:00   \n",
       "1                                 Bloomberg  economy  2008-09-20 00:00:00   \n",
       "2                                 Bloomberg  economy  2012-01-28 00:00:00   \n",
       "3                                  RTT News  economy  2015-03-01 00:06:00   \n",
       "4  The Nation - Thailand&#39;s English news  economy  2015-03-01 00:11:00   \n",
       "\n",
       "   Facebook  GooglePlus  LinkedIn  SentimentTitle  SentimentHeadline  \n",
       "0        -1          -1        -1        0.000000          -0.053300  \n",
       "1        -1          -1        -1        0.208333          -0.156386  \n",
       "2        -1          -1        -1       -0.425210           0.139754  \n",
       "3        -1          -1        -1        0.000000           0.026064  \n",
       "4        -1          -1        -1        0.000000           0.141084  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first five rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to find out the missing values in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDLink</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Headline</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Source</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Topic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PublishDate</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GooglePlus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SentimentTitle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SentimentHeadline</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index    0\n",
       "0              IDLink    0\n",
       "1               Title    0\n",
       "2            Headline    0\n",
       "3              Source  175\n",
       "4               Topic    0\n",
       "5         PublishDate    0\n",
       "6            Facebook    0\n",
       "7          GooglePlus    0\n",
       "8            LinkedIn    0\n",
       "9      SentimentTitle    0\n",
       "10  SentimentHeadline    0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe of missing values present in columns\n",
    "missing_val = pd.DataFrame(train.isnull().sum())\n",
    "# resetting index\n",
    "missing_val = missing_val.reset_index()\n",
    "missing_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in the columns except source it has 175 missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDLink           0\n",
       "Title            0\n",
       "Headline         0\n",
       "Source         101\n",
       "Topic            0\n",
       "PublishDate      0\n",
       "Facebook         0\n",
       "GooglePlus       0\n",
       "LinkedIn         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55932 entries, 0 to 55931\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   IDLink             55932 non-null  object \n",
      " 1   Title              55932 non-null  object \n",
      " 2   Headline           55932 non-null  object \n",
      " 3   Source             55757 non-null  object \n",
      " 4   Topic              55932 non-null  object \n",
      " 5   PublishDate        55932 non-null  object \n",
      " 6   Facebook           55932 non-null  int64  \n",
      " 7   GooglePlus         55932 non-null  int64  \n",
      " 8   LinkedIn           55932 non-null  int64  \n",
      " 9   SentimentTitle     55932 non-null  float64\n",
      " 10  SentimentHeadline  55932 non-null  float64\n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Info\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37288 entries, 0 to 37287\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   IDLink       37288 non-null  object\n",
      " 1   Title        37288 non-null  object\n",
      " 2   Headline     37288 non-null  object\n",
      " 3   Source       37187 non-null  object\n",
      " 4   Topic        37288 non-null  object\n",
      " 5   PublishDate  37288 non-null  object\n",
      " 6   Facebook     37288 non-null  int64 \n",
      " 7   GooglePlus   37288 non-null  int64 \n",
      " 8   LinkedIn     37288 non-null  int64 \n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55932, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We have 55932 instances and 11 columns here in our training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now splitting into x_train and y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train and y_train titles\n",
    "X_train_title = train.loc[:,'Title'].values\n",
    "y_train_title = train.loc[:,['SentimentTitle']].values\n",
    "\n",
    "# x_train_headline and y_train_headline\n",
    "X_train_headline = train.loc[:,'Headline'].values\n",
    "y_train_headline = train.loc[:,['SentimentHeadline']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introducing x_train title and headline \n",
    "X_test_title = test.loc[:,'Title'].values\n",
    "X_test_headline = test.loc[:,'Headline'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating title dataframe\n",
    "title_df=pd.DataFrame()\n",
    "title_df['X_train_title']=X_train_title\n",
    "title_df['y_train_title']=y_train_title\n",
    "\n",
    "# creating headline dataframe \n",
    "headline_df=pd.DataFrame()\n",
    "headline_df['X_train_headline']=X_train_headline\n",
    "headline_df['y_train_headline']=y_train_headline\n",
    "\n",
    "# creating test dataframe\n",
    "test_df=pd.DataFrame()\n",
    "test_df['X_test_title']=X_test_title\n",
    "test_df['X_test_headline']=X_test_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function for preprocessing\n",
    "def preprocess_text(texts):\n",
    "    texts = texts.lower() \n",
    "    texts = re.sub(r'[^\\x00-\\x7F]+',' ', texts) \n",
    "    words = texts.split()\n",
    "    words = filter(lambda x: x[0]!= '@' , texts.split()) \n",
    "    words = [word for word in words if word not in set(stopwords.words('english'))] \n",
    "    texts = \" \".join(words)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Danish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_train_title</th>\n",
       "      <th>y_train_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>obama lays wreath arlington national cemetery</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>look health chinese economy</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nouriel roubini: global economy back 2008</td>\n",
       "      <td>-0.425210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   X_train_title  y_train_title\n",
       "0  obama lays wreath arlington national cemetery       0.000000\n",
       "1                    look health chinese economy       0.208333\n",
       "2      nouriel roubini: global economy back 2008      -0.425210"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this will give preprocessed texts\n",
    "title_df['X_train_title'] = title_df.X_train_title.apply(preprocess_text)\n",
    "display(title_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_train_headline</th>\n",
       "      <th>y_train_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>obama lays wreath arlington national cemetery....</td>\n",
       "      <td>-0.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tim haywood, investment director business-unit...</td>\n",
       "      <td>-0.156386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nouriel roubini, nyu professor chairman roubin...</td>\n",
       "      <td>0.139754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finland's economy expanded marginally three mo...</td>\n",
       "      <td>0.026064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tourism public spending continued boost econom...</td>\n",
       "      <td>0.141084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    X_train_headline  y_train_headline\n",
       "0  obama lays wreath arlington national cemetery....         -0.053300\n",
       "1  tim haywood, investment director business-unit...         -0.156386\n",
       "2  nouriel roubini, nyu professor chairman roubin...          0.139754\n",
       "3  finland's economy expanded marginally three mo...          0.026064\n",
       "4  tourism public spending continued boost econom...          0.141084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# headline preprocessing texts\n",
    "headline_df['X_train_headline'] = headline_df.X_train_headline.apply(preprocess_text)\n",
    "display(headline_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_test_title</th>\n",
       "      <th>X_test_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sliding economy: fg fights back n3trn tsa funds</td>\n",
       "      <td>2016 budget passed national assembly n3trillio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>microsoft shows hololens bring distant family ...</td>\n",
       "      <td>recent microsoft research video shows $3000 au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft twitter robot praises hitler, trump ...</td>\n",
       "      <td>* microsoft teamed bing create taytweets, acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flood central bank moves can't get world econo...</td>\n",
       "      <td>central bankers managed steer world economy cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usd/jpy: bears lining mixed u.s. economy outlook</td>\n",
       "      <td>however, streak seven-day gains might end mark...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        X_test_title  \\\n",
       "0    sliding economy: fg fights back n3trn tsa funds   \n",
       "1  microsoft shows hololens bring distant family ...   \n",
       "2  microsoft twitter robot praises hitler, trump ...   \n",
       "3  flood central bank moves can't get world econo...   \n",
       "4   usd/jpy: bears lining mixed u.s. economy outlook   \n",
       "\n",
       "                                     X_test_headline  \n",
       "0  2016 budget passed national assembly n3trillio...  \n",
       "1  recent microsoft research video shows $3000 au...  \n",
       "2  * microsoft teamed bing create taytweets, acco...  \n",
       "3  central bankers managed steer world economy cl...  \n",
       "4  however, streak seven-day gains might end mark...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test headline preprocessing texts\n",
    "test_df['X_test_title'] = test_df.X_test_title.apply(preprocess_text)\n",
    "test_df['X_test_headline'] = test_df.X_test_headline.apply(preprocess_text)\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('C:/Users/Danish/Desktop/ZS_associates/dataset/glove.6b.50d.txt','r',encoding = 'utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing title\n",
    "max_len_title = title_df.X_train_title.apply(lambda x: len(x.split())).max()\n",
    "\n",
    "tok_title = Tokenizer()\n",
    "tok_title.fit_on_texts(title_df.X_train_title)\n",
    "vocab_size_title = len(tok_title.word_index) + 1\n",
    "encoded_title = tok_title.texts_to_sequences(title_df.X_train_title)\n",
    "padded_title = pad_sequences(encoded_title, maxlen=max_len_title, padding='post')\n",
    "\n",
    "vocab_size_title = len(tok_title.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embedding_matrix = np.zeros((vocab_size_title, 50))\n",
    "for word, i in tok_title.word_index.items():\n",
    "    t_embedding_vector = embeddings_index.get(word)\n",
    "    if t_embedding_vector is not None:\n",
    "        title_embedding_matrix[i] = t_embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing headline\n",
    "max_len_headline = headline_df.X_train_headline.apply(lambda x: len(x.split())).max()\n",
    "\n",
    "tok_headline = Tokenizer()\n",
    "tok_headline.fit_on_texts(headline_df.X_train_headline)\n",
    "vocab_size_headline = len(tok_headline.word_index) + 1\n",
    "encoded_headline = tok_headline.texts_to_sequences(headline_df.X_train_headline)\n",
    "padded_headline = pad_sequences(encoded_headline, maxlen=max_len_headline, padding='post')\n",
    "\n",
    "vocab_size_headline = len(tok_headline.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_embedding_matrix = np.zeros((vocab_size_headline, 50))\n",
    "for word, i in tok_headline.word_index.items():\n",
    "    h_embedding_vector = embeddings_index.get(word)\n",
    "    if h_embedding_vector is not None:\n",
    "        headline_embedding_matrix[i] = h_embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing test_title\n",
    "test_max_len_title = test_df.X_test_title.apply(lambda x: len(x.split())).max()\n",
    "\n",
    "test_tok_title = Tokenizer()\n",
    "test_tok_title.fit_on_texts(test_df.X_test_title)\n",
    "test_vocab_size_title = len(test_tok_title.word_index) + 1\n",
    "test_encoded_title = test_tok_title.texts_to_sequences(test_df.X_test_title)\n",
    "test_padded_title = pad_sequences(test_encoded_title, maxlen=test_max_len_title, padding='post')\n",
    "\n",
    "test_vocab_size_title = len(test_tok_title.word_index) + 1\n",
    "\n",
    "test_max_len_headline = test_df.X_test_headline.apply(lambda x: len(x.split())).max()\n",
    "\n",
    "# tokenizing test_headline\n",
    "test_tok_headline = Tokenizer()\n",
    "test_tok_headline.fit_on_texts(test_df.X_test_headline)\n",
    "test_vocab_size_headline = len(test_tok_headline.word_index) + 1\n",
    "test_encoded_headline = test_tok_headline.texts_to_sequences(test_df.X_test_headline)\n",
    "test_padded_headline = pad_sequences(test_encoded_headline, maxlen=test_max_len_headline, padding='post')\n",
    "\n",
    "test_vocab_size_headline = len(test_tok_headline.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37288, 53)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_padded_headline.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test values randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_title, x_valid_title, Y_train_title, y_valid_title = train_test_split(padded_title, y_train_title,\n",
    "                                                                              shuffle = True, test_size = 0.1)\n",
    "x_train_headline, x_valid_headline, Y_train_headline, y_valid_headline = train_test_split(padded_headline, y_train_headline,\n",
    "                                                                                          shuffle = True, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import math\n",
    "from math import exp\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hyperbolic tan\n",
    "def mod_tanh(x):\n",
    "    return K.tanh(0.6*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Title Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_model = Sequential()\n",
    "title_model.add(Embedding(vocab_size_title, 50, input_length=max_len_title, weights=[title_embedding_matrix], trainable=True))\n",
    "title_model.add(Bidirectional(LSTM(20, return_sequences=True)))\n",
    "title_model.add(Dropout(0.3))\n",
    "title_model.add(BatchNormalization())\n",
    "title_model.add(Bidirectional(LSTM(20, return_sequences=True)))\n",
    "title_model.add(Dropout(0.3))\n",
    "title_model.add(BatchNormalization())\n",
    "title_model.add(Bidirectional(LSTM(20)))\n",
    "title_model.add(Dropout(0.3))\n",
    "title_model.add(BatchNormalization())\n",
    "title_model.add(Dense(64, activation='relu'))\n",
    "title_model.add(Dense(64, activation='relu'))\n",
    "title_model.add(Dense(1, activation=mod_tanh))\n",
    "title_model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Headline Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_model = Sequential()\n",
    "headline_model.add(Embedding(vocab_size_headline, 50, input_length=max_len_headline, weights=[headline_embedding_matrix], trainable=True))\n",
    "headline_model.add(Bidirectional(LSTM(20, return_sequences=True)))\n",
    "headline_model.add(Dropout(0.3))\n",
    "headline_model.add(BatchNormalization())\n",
    "headline_model.add(Bidirectional(LSTM(20, return_sequences=True)))\n",
    "headline_model.add(Dropout(0.3))\n",
    "headline_model.add(BatchNormalization())\n",
    "headline_model.add(Bidirectional(LSTM(20)))\n",
    "headline_model.add(Dropout(0.3))\n",
    "headline_model.add(BatchNormalization())\n",
    "headline_model.add(Dense(64, activation='relu'))\n",
    "headline_model.add(Dense(64, activation='relu'))\n",
    "headline_model.add(Dense(1, activation=mod_tanh))\n",
    "headline_model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "1574/1574 [==============================] - 143s 77ms/step - loss: 0.0208 - mse: 0.0208 - mae: 0.1073\n",
      "Epoch 2/9\n",
      "1574/1574 [==============================] - 133s 85ms/step - loss: 0.0151 - mse: 0.0151 - mae: 0.09031s - loss: 0.0151 - mse: 0.015\n",
      "Epoch 3/9\n",
      "1574/1574 [==============================] - 129s 82ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0715\n",
      "Epoch 4/9\n",
      "1574/1574 [==============================] - 139s 89ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.06083s \n",
      "Epoch 5/9\n",
      "1574/1574 [==============================] - 97s 62ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0557\n",
      "Epoch 6/9\n",
      "1574/1574 [==============================] - 118s 75ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0521\n",
      "Epoch 7/9\n",
      "1574/1574 [==============================] - 131s 83ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0491\n",
      "Epoch 8/9\n",
      "1574/1574 [==============================] - 134s 85ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0463\n",
      "Epoch 9/9\n",
      "1574/1574 [==============================] - 121s 77ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0441\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    title_model.fit(x_train_title, Y_train_title, epochs = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1574/1574 [==============================] - 297s 185ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0470\n",
      "Epoch 2/10\n",
      "1574/1574 [==============================] - 273s 174ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0452\n",
      "Epoch 3/10\n",
      "1574/1574 [==============================] - 270s 172ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0423\n",
      "Epoch 4/10\n",
      "1574/1574 [==============================] - 264s 168ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0404\n",
      "Epoch 5/10\n",
      "1574/1574 [==============================] - 286s 182ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0381\n",
      "Epoch 6/10\n",
      "1574/1574 [==============================] - 276s 175ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.03651s - loss: 0.0 - ETA: 7s -\n",
      "Epoch 7/10\n",
      "1574/1574 [==============================] - 283s 180ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0345s - loss: 0.0022 - mse:\n",
      "Epoch 8/10\n",
      "1574/1574 [==============================] - 282s 179ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0328\n",
      "Epoch 9/10\n",
      "1574/1574 [==============================] - 276s 175ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0315\n",
      "Epoch 10/10\n",
      "1574/1574 [==============================] - 252s 160ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0298\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    headline_model.fit(x_train_headline, Y_train_headline, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validity of title prediction\n",
    "title_valid_pred = title_model.predict(x_valid_title)\n",
    "\n",
    "# validity of headline prediction \n",
    "headline_valid_pred = headline_model.predict(x_valid_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models\n",
    "title_model.save('title.h5')\n",
    "\n",
    "headline_model.save('headline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Evaluation metrics is: 0.932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Mean absolute error fot title\n",
    "mae_title=mean_absolute_error(y_valid_title,title_valid_pred)\n",
    "\n",
    "# Mean absolute error for headline\n",
    "mae_headline=mean_absolute_error(y_valid_headline,headline_valid_pred)\n",
    "\n",
    "# Evaluation Metrics\n",
    "score=1-((0.4*mae_title)+(0.6*mae_headline))\n",
    "print(f'The Evaluation metrics is: {round(score,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of title\n",
    "pred_title=title_model.predict(test_padded_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings                                                                                \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37288, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_headline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37288, 1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = test_padded_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37288, 50)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1, D2 = test_padded_headline.shape\n",
    "A[:, 0] = A[:, D2-3] \n",
    "A.resize((D1, D2-3), refcheck=False)\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of headline \n",
    "pred_headline=headline_model.predict(test_padded_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe as per required format\n",
    "submission1=pd.DataFrame()\n",
    "submission1['IDLink']=test['IDLink'].to_list()\n",
    "submission1['SentimentTitle']=pred_title\n",
    "submission1['SentimentHeadline']=pred_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission1.to_csv('Submissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission1.to_csv(os.path.join('C:/Users/Danish/Desktop/ZS_associates/dataset','Submission.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
